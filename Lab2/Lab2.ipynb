{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15702f50-2e8b-4674-b31b-340969173c06",
   "metadata": {},
   "source": [
    "# Lab Assignment 2: Data Reading and Processing\n",
    "**Name:** Eva Santana\n",
    "\n",
    "**Date:** Oct 13 2025\n",
    "\n",
    "## Introduction\n",
    "This project focuses on reading, cleaning, and merging three fragmented and partially damaged datasets (`fortune500.csv`, `lines.json`, and `unstructureddata.txt`).  \n",
    "I standardize their formats, handle missing values, and generate summary statistics such as total data volume, missing entries, and top companies by revenue and profit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff98c9da-af99-412a-8349-c31ba61b2168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import json\n",
    "\n",
    "file_path = [\"fortune500.csv\", \"lines.json\", \"unstructureddata.txt\"]\n",
    "good_data, bad_data = [], [] \n",
    "\n",
    "# -----------------------------------\n",
    "# Read CSV file safely\n",
    "# -----------------------------------\n",
    "\n",
    "with open(file_path[0], mode='r', encoding='utf-8') as file:\n",
    "    csv_reader = csv.reader(file)\n",
    "    header = next(csv_reader, None)\n",
    "\n",
    "    for row in csv_reader:\n",
    "        if not row or len(row) < 5:\n",
    "            continue\n",
    "\n",
    "        year = row[0]\n",
    "        rank = row[1]\n",
    "        company = row[2]\n",
    "        revenue = row[3]\n",
    "        profit = row[4]\n",
    "\n",
    "        bad = False\n",
    "\n",
    "        # Check for missing or NaN values safely\n",
    "        if pd.isna(year) or pd.isna(rank) or pd.isna(company) or pd.isna(revenue) or pd.isna(profit):\n",
    "            bad = True\n",
    "        else: \n",
    "            year_val = pd.to_numeric(year, errors = 'coerce')\n",
    "            rank_val = pd.to_numeric(rank, errors = 'coerce')\n",
    "            revenue_val = pd.to_numeric(revenue, errors = 'coerce')\n",
    "            profit_val = pd.to_numeric(profit, errors = 'coerce')\n",
    "\n",
    "            if pd.isna(year_val) or pd.isna(rank_val) or pd.isna(revenue_val) or pd.isna(profit_val):\n",
    "                bad = True \n",
    "\n",
    "        if bad:\n",
    "            bad_data.append(row)\n",
    "        else:\n",
    "            good_data.append(row)\n",
    "                \n",
    "# -----------------------------------\n",
    "# Read JSON Lines file safely\n",
    "# -----------------------------------\n",
    "title = ['Year', 'Rank', 'Company', 'Revenue (in millions)', 'Profit (in millions)']\n",
    "\n",
    "with open(file_path[1], 'r') as file:\n",
    "    for line in file: \n",
    "        try: \n",
    "            json_obj = json.loads(line.strip())\n",
    "\n",
    "            for key in title: \n",
    "                if key not in json_obj:\n",
    "                    json_obj[key] = None\n",
    "\n",
    "            row = [\n",
    "                json_obj['Year'],\n",
    "                json_obj['Rank'],\n",
    "                json_obj['Company'],\n",
    "                json_obj['Revenue (in millions)'],\n",
    "                json_obj['Profit (in millions)']]\n",
    "            # Check if any fields are missing or invalid numerically\n",
    "            bad = False\n",
    "            if any(pd.isna(val) for val in row):\n",
    "                bad = True\n",
    "            else:\n",
    "                # Try converting numeric fields\n",
    "                year_val = pd.to_numeric(json_obj['Year'], errors='coerce')\n",
    "                rank_val = pd.to_numeric(json_obj['Rank'], errors='coerce')\n",
    "                rev_val = pd.to_numeric(json_obj['Revenue (in millions)'], errors='coerce')\n",
    "                prof_val = pd.to_numeric(json_obj['Profit (in millions)'], errors='coerce')\n",
    "\n",
    "                if pd.isna(year_val) or pd.isna(rank_val) or pd.isna(rev_val) or pd.isna(prof_val):\n",
    "                    bad = True\n",
    "\n",
    "            if bad:\n",
    "                bad_data.append(row)\n",
    "            else:\n",
    "                good_data.append(row)\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            # Malformed JSON lines go straight to bad_data\n",
    "            bad_data.append([line.strip()])         \n",
    "\n",
    "# -----------------------------------\n",
    "# Read Unstructured Text file safely\n",
    "# -----------------------------------\n",
    "expected_keys = [\"Year\", \"Rank\", \"Company\", \"Revenue (in millions)\", \"Profit (in millions)\"]\n",
    "\n",
    "# Function to process a block of text and return a dictionary\n",
    "def process_block_with_damage(block):\n",
    "    entity = {key: None for key in expected_keys}\n",
    "    for item in block:\n",
    "        if \": \" in item:\n",
    "            key, value = item.split(\": \", 1)  # Split only on the first ': '\n",
    "            if key in entity:\n",
    "                entity[key] = value.strip()\n",
    "    return entity\n",
    "\n",
    "current_data = []\n",
    "with open(file_path[2], 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        if line.strip() == \"\":\n",
    "            if current_data:  # Process accumulated block\n",
    "                processed_data = process_block_with_damage(current_data)\n",
    "\n",
    "                # Convert to row format\n",
    "                row = [\n",
    "                    processed_data[\"Year\"],\n",
    "                    processed_data[\"Rank\"],\n",
    "                    processed_data[\"Company\"],\n",
    "                    processed_data[\"Revenue (in millions)\"],\n",
    "                    processed_data[\"Profit (in millions)\"]\n",
    "                ]\n",
    "\n",
    "                # Validate row (check missing or invalid numerics)\n",
    "                bad = False\n",
    "                if any(pd.isna(val) or val is None or val == \"\" for val in row):\n",
    "                    bad = True\n",
    "                else:\n",
    "                    year_val = pd.to_numeric(processed_data[\"Year\"], errors='coerce')\n",
    "                    rank_val = pd.to_numeric(processed_data[\"Rank\"], errors='coerce')\n",
    "                    rev_val = pd.to_numeric(processed_data[\"Revenue (in millions)\"], errors='coerce')\n",
    "                    prof_val = pd.to_numeric(processed_data[\"Profit (in millions)\"], errors='coerce')\n",
    "\n",
    "                    if pd.isna(year_val) or pd.isna(rank_val) or pd.isna(rev_val) or pd.isna(prof_val):\n",
    "                        bad = True\n",
    "\n",
    "                if bad:\n",
    "                    bad_data.append(row)\n",
    "                else:\n",
    "                    good_data.append(row)\n",
    "\n",
    "                current_data = []  # Reset for next block\n",
    "        else:\n",
    "            current_data.append(line.strip())\n",
    "\n",
    "    # Handle the last block if file doesnâ€™t end with a blank line\n",
    "    if current_data:\n",
    "        processed_data = process_block_with_damage(current_data)\n",
    "        row = [\n",
    "            processed_data[\"Year\"],\n",
    "            processed_data[\"Rank\"],\n",
    "            processed_data[\"Company\"],\n",
    "            processed_data[\"Revenue (in millions)\"],\n",
    "            processed_data[\"Profit (in millions)\"]\n",
    "        ]\n",
    "        bad = False\n",
    "        if any(pd.isna(val) or val is None or val == \"\" for val in row):\n",
    "            bad = True\n",
    "        else:\n",
    "            year_val = pd.to_numeric(processed_data[\"Year\"], errors='coerce')\n",
    "            rank_val = pd.to_numeric(processed_data[\"Rank\"], errors='coerce')\n",
    "            rev_val = pd.to_numeric(processed_data[\"Revenue (in millions)\"], errors='coerce')\n",
    "            prof_val = pd.to_numeric(processed_data[\"Profit (in millions)\"], errors='coerce')\n",
    "\n",
    "            if pd.isna(year_val) or pd.isna(rank_val) or pd.isna(rev_val) or pd.isna(prof_val):\n",
    "                bad = True\n",
    "\n",
    "        if bad:\n",
    "            bad_data.append(row)\n",
    "        else:\n",
    "            good_data.append(row)\n",
    "\n",
    " \n",
    "\n",
    "df_good = pd.DataFrame(good_data, columns=['Year', 'Rank', 'Company', 'Revenue', 'Profit'])\n",
    "df_bad = pd.DataFrame(bad_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b607b7fc-dad5-41e5-9b59-c85b9ea11eba",
   "metadata": {},
   "source": [
    "# Result \n",
    "- The aggregate data volume (Good data)\n",
    "\n",
    "This result was found using the len() function on the df_good dataframe, which counts the total number of valid rows.\n",
    "\n",
    "- Instances of missing data (Bad data)\n",
    "\n",
    "This result was found using the len() function on the df_bad dataframe, which counts the number of rows that contained missing or invalid entries.\n",
    "\n",
    "- The number of unique companies\n",
    "\n",
    "This result was found by accessing the 'Company' column from the df_good dataframe and using the unique() operation to determine how many distinct company names were present in the good dataset.\n",
    "\n",
    "- The company with the highest revenue from 1995 to 1998\n",
    "\n",
    "First, I filtered all rows where the 'Year' column was between 1995 and 1998 (inclusive). Then, I located the row with the maximum 'Revenue' value within this range to identify which company had the highest revenue during that period.\n",
    "\n",
    "- The company with the highest profit from 1995 to 1998\n",
    "\n",
    "After filtering for the years 1995â€“1998, I found the row with the maximum 'Profit' value to determine the company that achieved the highest profit within that same time frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d539c981-b010-4140-a37f-5eb4340c1539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Total Good Data</td>\n",
       "      <td>42590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total Bad Data</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unique Companies</td>\n",
       "      <td>2359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Top Revenue Company (1995â€“1998)</td>\n",
       "      <td>General Motors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Top Revenue Value (in millions)</td>\n",
       "      <td>178174.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Top Profit Company (1995â€“1998)</td>\n",
       "      <td>Exxon Mobil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Top Profit Value (in millions)</td>\n",
       "      <td>8460.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Metric           Value\n",
       "0                  Total Good Data           42590\n",
       "1                   Total Bad Data            4759\n",
       "2                 Unique Companies            2359\n",
       "3  Top Revenue Company (1995â€“1998)  General Motors\n",
       "4  Top Revenue Value (in millions)        178174.0\n",
       "5   Top Profit Company (1995â€“1998)     Exxon Mobil\n",
       "6   Top Profit Value (in millions)          8460.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -----------------------------------\n",
    "# Data Statistics Section\n",
    "# -----------------------------------\n",
    "\n",
    "# Total number of valid (good) rows\n",
    "total_good = len(df_good)\n",
    "\n",
    "# Total number of invalid (bad) rows\n",
    "total_bad = len(df_bad)\n",
    "\n",
    "# Number of unique companies\n",
    "unique_companies = df_good['Company'].nunique()\n",
    "\n",
    "# Company with highest revenue between 1995â€“1998\n",
    "df_good['Year'] = pd.to_numeric(df_good['Year'])\n",
    "df_good['Revenue'] = pd.to_numeric(df_good['Revenue'])\n",
    "df_good['Profit'] = pd.to_numeric(df_good['Profit'])\n",
    "\n",
    "# Filter for 1995-1998\n",
    "df_95_98 = df_good[(df_good['Year'] >= 1995) & (df_good['Year'] <= 1998)]\n",
    "\n",
    "# Find top revenue company\n",
    "top_revenue_row = df_95_98.loc[df_95_98['Revenue'].idxmax()]\n",
    "top_revenue_company = top_revenue_row['Company']\n",
    "top_revenue_value = top_revenue_row['Revenue']\n",
    "\n",
    "# Company with highest profit between 1995â€“1998\n",
    "top_profit_row = df_95_98.loc[df_95_98['Profit'].idxmax()]\n",
    "top_profit_company = top_profit_row['Company']\n",
    "top_profit_value = top_profit_row['Profit']\n",
    "\n",
    "# Combine results into a single summary DataFrame\n",
    "Results_Combine = pd.DataFrame({\n",
    "    'Metric': [\n",
    "        'Total Good Data',\n",
    "        'Total Bad Data',\n",
    "        'Unique Companies',\n",
    "        'Top Revenue Company (1995â€“1998)',\n",
    "        'Top Revenue Value (in millions)',\n",
    "        'Top Profit Company (1995â€“1998)',\n",
    "        'Top Profit Value (in millions)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        total_good,\n",
    "        total_bad,\n",
    "        unique_companies,\n",
    "        top_revenue_company,\n",
    "        top_revenue_value,\n",
    "        top_profit_company,\n",
    "        top_profit_value\n",
    "    ]\n",
    "})\n",
    "\n",
    "Results_Combine.to_csv(\"Results_Combine.csv\", index=False)\n",
    "\n",
    "\n",
    "Results_Combine\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df935e3f-31ef-49e9-bc9c-db1c0cc714e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
